services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    # ports:
    #   - "${OLLAMA_HOST_PORT}:${OLLAMA_PORT}"    
    expose:
      - ${OLLAMA_PORT}
    volumes:
      - ollama-data:/root/.ollama
    environment:
      # [필수 추가] Ollama가 모든 네트워크 인터페이스(Docker 내부)에서 수신하도록 설정
      # 기본 포트가 11434라면 ${OLLAMA_PORT}는 11434와 일치해야 합니다.
      - OLLAMA_HOST=0.0.0.0:${OLLAMA_PORT}
      
      # [GPU 필수] 컨테이너가 할당된 GPU를 사용하도록 명시
      - NVIDIA_VISIBLE_DEVICES=all
    networks:
      infra_net:
        ipv4_address: 172.19.0.40
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    labels:
      - "traefik.enable=true"
      
      # Ollama API 라우터 (https://ollama.hy-home.local)
      - "traefik.http.routers.ollama.rule=Host(`ollama.${DEFAULT_URL}`)"
      - "traefik.http.routers.ollama.entrypoints=websecure"
      - "traefik.http.routers.ollama.tls=true"
      
      # [중요] 내부 포트 11434 연결
      - "traefik.http.services.ollama.loadbalancer.server.port=${OLLAMA_PORT}"
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    ports:
      - "${QDRANT_HOST_PORT}:${QDRANT_PORT}"
    environment:
      - QDRANT__TELEMETRY_DISABLED=false # 메트릭 수집 활성화
    volumes:
      - qdrant-data:/qdrant/storage
    restart: unless-stopped
    networks:
      infra_net:
        ipv4_address: 172.19.0.41
    # Qdrant 대시보드(Web UI)를 보고 싶다면 아래 라벨 주석 해제
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.qdrant.rule=Host(`qdrant.${DEFAULT_URL}`)"
      - "traefik.http.routers.qdrant.entrypoints=websecure"
      - "traefik.http.routers.qdrant.tls=true"
      - "traefik.http.services.qdrant.loadbalancer.server.port=${QDRANT_PORT}"
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # 2. Open WebUI 서비스 (선택 사항: ChatGPT 같은 웹 인터페이스)
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    # ports:
    #   - "${OLLAMA_WEBUI_HOST_PORT}:${OLLAMA_WEBUI_PORT}" # 브라우저에서 localhost:3000 으로 접속
    environment:
      - OLLAMA_BASE_URL=http://ollama:${OLLAMA_PORT} # 도커 네트워크 내부 통신
      # --- RAG 설정 추가 ---
      # 벡터 DB 연결 설정
      - VECTOR_DB_URL=http://qdrant:${QDRANT_PORT}
      # 임베딩(텍스트를 숫자로 변환) 작업을 Ollama에게 맡김
      - RAG_EMBEDDING_ENGINE=ollama
      - RAG_EMBEDDING_MODEL=mxbai-embed-large
    volumes:
      - ollama-webui:/app/backend/data
    depends_on:
      - ollama
      - qdrant
    restart: unless-stopped
    networks:
      infra_net:
        ipv4_address: 172.19.0.42
    labels:
      - "traefik.enable=true"
      
      # 챗봇 UI 라우터 (https://chat.hy-home.local)
      - "traefik.http.routers.open-webui.rule=Host(`chat.${DEFAULT_URL}`)"
      - "traefik.http.routers.open-webui.entrypoints=websecure"
      - "traefik.http.routers.open-webui.tls=true"
      
      # [중요] 내부 포트 8080 연결 (Open WebUI 기본 포트)
      - "traefik.http.services.open-webui.loadbalancer.server.port=8080"
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"
  
  ollama-exporter:
    image: lucabecker42/ollama-exporter:latest
    container_name: ollama-exporter
    environment:
      - OLLAMA_HOST=ollama:${OLLAMA_PORT}
    ports:
      - "${OLLAMA_EXPORTER_HOST_PORT}:${OLLAMA_EXPORTER_PORT}"   # /metrics
    restart: unless-stopped
    networks:
      infra_net:
        ipv4_address: 172.19.0.43
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"