# Usage
#   Start:          docker compose up
#   With helpers:   docker compose -f docker-compose.yml -f ./dev/docker-compose.dev.yml up
#   Stop:           docker compose down
#   Destroy:        docker compose -f docker-compose.yml -f ./dev/docker-compose.dev.yml down -v --remove-orphans

name: supabase
version: "3.8"

services:
  supabase-studio:
    env_file:
      - ./.env.supabase
    container_name: supabase-studio
    hostname: supabase-studio
    image: supabase/studio:20240701-05dfbec
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD",
          "node",
          "-e",
          "require('http').get('http://localhost:${SUPABASE_STUDIO_PORT}/api/profile', (r) => {if (r.statusCode !== 200) throw new Error(r.statusCode)})",
        ]
      timeout: 5s
      interval: 5s
      retries: 3
    depends_on:
      supabase-analytics:
        condition: service_healthy
    environment:
      STUDIO_PG_META_URL: http://supabase-meta:${SUPABASE_META_PORT}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}

      DEFAULT_ORGANIZATION_NAME: ${STUDIO_DEFAULT_ORGANIZATION}
      DEFAULT_PROJECT_NAME: ${STUDIO_DEFAULT_PROJECT}

      SUPABASE_URL: http://supabase-kong:${SUPABASE_KONG_HTTP_PORT}
      SUPABASE_PUBLIC_URL: ${SUPABASE_PUBLIC_URL}
      SUPABASE_ANON_KEY: ${ANON_KEY}
      SUPABASE_SERVICE_KEY: ${SERVICE_ROLE_KEY}
      AUTH_JWT_SECRET: ${JWT_SECRET}

      # LOGFLARE_API_KEY: ${LOGFLARE_API_KEY}
      LOGFLARE_URL: http://supabase-analytics:${SUPABASE_ANALYTICS_PORT}
      NEXT_PUBLIC_ENABLE_LOGS: true
      # Comment to use Big Query backend for analytics
      NEXT_ANALYTICS_BACKEND_PROVIDER: postgres
    networks:
      - nt-supabase
      - nt-databases
      - nt-storage
      - nt-observability
      - nt-webserver

  supabase-kong:
    env_file:
      - ./.env.supabase
    container_name: supabase-kong
    image: kong:2.8.1
    restart: unless-stopped
    # https://unix.stackexchange.com/a/294837
    entrypoint: bash -c 'eval "echo \"$$(cat ~/temp.yml)\"" > ~/kong.yml && /docker-entrypoint.sh kong docker-start'
    ports:
      - ${KONG_HTTP_PORT}:${SUPABASE_KONG_HTTP_PORT}/tcp
      - ${KONG_HTTPS_PORT}:${SUPABASE_KONG_HTTPS_PORT}/tcp
    depends_on:
      supabase-analytics:
        condition: service_healthy
    environment:
      KONG_DATABASE: "off"
      KONG_DECLARATIVE_CONFIG: /home/kong/kong.yml
      # https://github.com/supabase/cli/issues/14
      KONG_DNS_ORDER: LAST,A,CNAME
      KONG_PLUGINS: request-transformer,cors,key-auth,acl,basic-auth
      KONG_NGINX_PROXY_PROXY_BUFFER_SIZE: 160k
      KONG_NGINX_PROXY_PROXY_BUFFERS: 64 160k
      SUPABASE_ANON_KEY: ${ANON_KEY}
      SUPABASE_SERVICE_KEY: ${SERVICE_ROLE_KEY}
      DASHBOARD_USERNAME: ${SUPABASE_DASHBOARD_USERNAME}
      DASHBOARD_PASSWORD: ${SUPABASE_DASHBOARD_PASSWORD}
    volumes:
      # https://github.com/supabase/supabase/issues/12661
      - supabase-api-volume:/home/kong
    networks:
      - nt-supabase
      - nt-databases
      - nt-storage
      - nt-observability
      - nt-webserver

  supabase-auth:
    env_file:
      - ./.env.supabase
    container_name: supabase-auth
    image: supabase/gotrue:v2.151.0
    depends_on:
      supabase-analytics:
        condition: service_healthy
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:${SUPABASE_GOTRUE_API_PORT}/health",
        ]
      timeout: 5s
      interval: 5s
      retries: 3
    restart: unless-stopped
    environment:
      GOTRUE_API_HOST: ${SUPABASE_GOTRUE_API_HOST}
      GOTRUE_API_PORT: ${SUPABASE_GOTRUE_API_PORT}
      API_EXTERNAL_URL: ${SUPABASE_API_EXTERNAL_URL}

      GOTRUE_DB_DRIVER: postgres
      GOTRUE_DB_DATABASE_URL: postgres://supabase_auth_admin:${POSTGRES_PASSWORD}@${POSTGRES_HOSTNAME}:${POSTGRES_PORT}/${SUPABASE_POSTGRES_DATABASE}

      GOTRUE_SITE_URL: ${SUPABASE_SITE_URL}
      GOTRUE_URI_ALLOW_LIST: ${ADDITIONAL_REDIRECT_URLS}
      GOTRUE_DISABLE_SIGNUP: ${DISABLE_SIGNUP}

      GOTRUE_JWT_ADMIN_ROLES: service_role
      GOTRUE_JWT_AUD: authenticated
      GOTRUE_JWT_DEFAULT_GROUP_NAME: authenticated
      GOTRUE_JWT_EXP: ${JWT_EXPIRY}
      GOTRUE_JWT_SECRET: ${JWT_SECRET}

      GOTRUE_EXTERNAL_EMAIL_ENABLED: ${ENABLE_EMAIL_SIGNUP}
      GOTRUE_EXTERNAL_ANONYMOUS_USERS_ENABLED: ${ENABLE_ANONYMOUS_USERS}
      GOTRUE_MAILER_AUTOCONFIRM: ${ENABLE_EMAIL_AUTOCONFIRM}
      # GOTRUE_MAILER_SECURE_EMAIL_CHANGE_ENABLED: true
      # GOTRUE_SMTP_MAX_FREQUENCY: 1s
      GOTRUE_SMTP_ADMIN_EMAIL: ${MAIL_USERNAME}
      GOTRUE_SMTP_HOST: ${MAIL_HOST}
      GOTRUE_SMTP_PORT: ${MAIL_PORT}
      GOTRUE_SMTP_USER: ${MAIL_USERNAME}
      GOTRUE_SMTP_PASS: ${MAIL_PASSWORD}
      GOTRUE_SMTP_SENDER_NAME: ${MAIL_SERVER_NAME}
      GOTRUE_MAILER_URLPATHS_INVITE: ${MAILER_URLPATHS_INVITE}
      GOTRUE_MAILER_URLPATHS_CONFIRMATION: ${MAILER_URLPATHS_CONFIRMATION}
      GOTRUE_MAILER_URLPATHS_RECOVERY: ${MAILER_URLPATHS_RECOVERY}
      GOTRUE_MAILER_URLPATHS_EMAIL_CHANGE: ${MAILER_URLPATHS_EMAIL_CHANGE}

      GOTRUE_EXTERNAL_PHONE_ENABLED: ${ENABLE_PHONE_SIGNUP}
      GOTRUE_SMS_AUTOCONFIRM: ${ENABLE_PHONE_AUTOCONFIRM}
      # Uncomment to enable custom access token hook. You'll need to create a public.custom_access_token_hook function and grant necessary permissions.
      # See: https://supabase.com/docs/guides/auth/auth-hooks#hook-custom-access-token for details
      # GOTRUE_HOOK_CUSTOM_ACCESS_TOKEN_ENABLED="true"
      # GOTRUE_HOOK_CUSTOM_ACCESS_TOKEN_URI="pg-functions://postgres/public/custom_access_token_hook"

      # GOTRUE_HOOK_MFA_VERIFICATION_ATTEMPT_ENABLED="true"
      # GOTRUE_HOOK_MFA_VERIFICATION_ATTEMPT_URI="pg-functions://postgres/public/mfa_verification_attempt"

      # GOTRUE_HOOK_PASSWORD_VERIFICATION_ATTEMPT_ENABLED="true"
      # GOTRUE_HOOK_PASSWORD_VERIFICATION_ATTEMPT_URI="pg-functions://postgres/public/password_verification_attempt"
    networks:
      - nt-supabase
      - nt-databases
      - nt-storage
      - nt-observability
      - nt-webserver

  supabase-rest:
    env_file:
      - ./.env.supabase
    container_name: supabase-rest
    image: postgrest/postgrest:v12.2.0
    depends_on:
      supabase-analytics:
        condition: service_healthy
    restart: unless-stopped
    environment:
      PGRST_DB_URI: postgres://${DEFAULT_USERNAME}:${POSTGRES_PASSWORD}@${POSTGRES_HOSTNAME}:${POSTGRES_PORT}/${SUPABASE_POSTGRES_DATABASE}
      PGRST_DB_SCHEMAS: ${PGRST_DB_SCHEMAS}
      PGRST_DB_ANON_ROLE: anon
      PGRST_JWT_SECRET: ${JWT_SECRET}
      PGRST_DB_USE_LEGACY_GUCS: "false"
      PGRST_APP_SETTINGS_JWT_SECRET: ${JWT_SECRET}
      PGRST_APP_SETTINGS_JWT_EXP: ${JWT_EXPIRY}
    command: "postgrest"
    networks:
      - nt-supabase
      - nt-databases
      - nt-storage
      - nt-observability
      - nt-webserver

  supabase-realtime:
    env_file:
      - .env.supabase
    # This container name looks inconsistent but is correct because realtime constructs tenant id by parsing the subdomain
    container_name: realtime-dev.supabase-realtime
    image: supabase/realtime:v2.29.15
    depends_on:
      supabase-analytics:
        condition: service_healthy
    healthcheck:
      test:
        [
          "CMD",
          "curl",
          "-sSfL",
          "--head",
          "-o",
          "/dev/null",
          "-H",
          "Authorization: Bearer ${ANON_KEY}",
          "http://localhost:${SUPABASE_REALTIME_PORT}/api/tenants/realtime-dev/health",
        ]
      timeout: 5s
      interval: 5s
      retries: 3
    restart: unless-stopped
    environment:
      PORT: ${SUPABASE_REALTIME_PORT}
      DB_HOST: ${POSTGRES_HOSTNAME}
      DB_PORT: ${POSTGRES_PORT}
      DB_USER: ${DEFAULT_USERNAME}
      DB_PASSWORD: ${POSTGRES_PASSWORD}
      DB_NAME: ${SUPABASE_POSTGRES_DATABASE}
      DB_AFTER_CONNECT_QUERY: "SET search_path TO _realtime"
      DB_ENC_KEY: supabaserealtime
      API_JWT_SECRET: ${JWT_SECRET}
      SECRET_KEY_BASE: UpNVntn3cDxHJpq99YMc1T1AQgQpc8kfYTuRgBiYa15BLrx8etQoXz3gZv1/u2oq
      ERL_AFLAGS: -proto_dist inet_tcp
      DNS_NODES: "''"
      RLIMIT_NOFILE: "10000"
      APP_NAME: realtime
      SEED_SELF_HOST: true
    networks:
      - nt-supabase
      - nt-databases
      - nt-storage
      - nt-observability
      - nt-webserver

  # To use S3 backed storage: docker compose -f docker-compose.yml -f docker-compose.s3.yml up
  supabase-storage:
    env_file:
      - .env.supabase
    container_name: supabase-storage
    image: supabase/storage-api:v1.0.6
    depends_on:
      supabase-rest:
        condition: service_started
      supabase-imgproxy:
        condition: service_started
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:${SUPABASE_STORAGE_HEALTH_PORT}/status",
        ]
      timeout: 5s
      interval: 5s
      retries: 3
    restart: unless-stopped
    environment:
      ANON_KEY: ${ANON_KEY}
      SERVICE_KEY: ${SERVICE_ROLE_KEY}
      POSTGREST_URL: http://supabase-rest:${POSTGREST_PORT}
      PGRST_JWT_SECRET: ${JWT_SECRET}
      DATABASE_URL: postgres://${DEFAULT_USERNAME}:${POSTGRES_PASSWORD}@${POSTGRES_HOSTNAME}:${POSTGRES_PORT}/${SUPABASE_POSTGRES_DATABASE}
      FILE_SIZE_LIMIT: 52428800
      STORAGE_BACKEND: s3
      GLOBAL_S3_BUCKET: stub
      GLOBAL_S3_ENDPOINT: http://minio:${MINIO_PORT}
      GLOBAL_S3_PROTOCOL: http
      GLOBAL_S3_FORCE_PATH_STYLE: true
      AWS_ACCESS_KEY_ID: ${DEFAULT_USERNAME}
      AWS_SECRET_ACCESS_KEY: ${MINIO_PASSWORD}
      AWS_DEFAULT_REGION: stub
      FILE_STORAGE_BACKEND_PATH: /var/lib/storage
      TENANT_ID: stub
      # TODO: https://github.com/supabase/storage-api/issues/55
      REGION: stub
      ENABLE_IMAGE_TRANSFORMATION: "true"
      IMGPROXY_URL: http://imgproxy:${SUPABASE_IMPROXY_PORT}
    volumes:
      - ./volumes/storage:/var/lib/storage:z
    networks:
      - nt-supabase
      - nt-databases
      - nt-storage
      - nt-observability
      - nt-webserver

  supabase-imgproxy:
    env_file:
      - .env.supabase
    container_name: supabase-imgproxy
    image: darthsim/imgproxy:v3.8.0
    healthcheck:
      test: ["CMD", "imgproxy", "health"]
      timeout: 5s
      interval: 5s
      retries: 3
    environment:
      IMGPROXY_BIND: ":${SUPABASE_IMPROXY_PORT}"
      # IMGPROXY_LOCAL_FILESYSTEM_ROOT: /
      IMGPROXY_USE_ETAG: "true"
      IMGPROXY_ENABLE_WEBP_DETECTION: ${IMGPROXY_ENABLE_WEBP_DETECTION}
    networks:
      - nt-supabase
      - nt-databases
      - nt-storage
      - nt-observability
      - nt-webserver

  supabase-meta:
    env_file:
      - .env.supabase
    container_name: supabase-meta
    image: supabase/postgres-meta:v0.83.2
    depends_on:
      supabase-analytics:
        condition: service_healthy
    restart: unless-stopped
    environment:
      PG_META_PORT: 8080
      PG_META_DB_HOST: ${POSTGRES_HOSTNAME}
      PG_META_DB_PORT: ${POSTGRES_PORT}
      PG_META_DB_NAME: ${SUPABASE_POSTGRES_DATABASE}
      PG_META_DB_USER: ${DEFAULT_USERNAME}
      PG_META_DB_PASSWORD: ${POSTGRES_PASSWORD}
    networks:
      - nt-supabase
      - nt-databases
      - nt-storage
      - nt-observability
      - nt-webserver

  supabase-functions:
    env_file:
      - .env.supabase
    container_name: supabase-edge-functions
    image: supabase/edge-runtime:v1.54.10
    restart: unless-stopped
    depends_on:
      supabase-analytics:
        condition: service_healthy
    environment:
      JWT_SECRET: ${JWT_SECRET}
      SUPABASE_URL: http://supabase-kong:${SUPABASE_KONG_HTTP_PORT}
      SUPABASE_ANON_KEY: ${ANON_KEY}
      SUPABASE_SERVICE_ROLE_KEY: ${SERVICE_ROLE_KEY}
      SUPABASE_DB_URL: postgresql://${POSTGRES_ROOT_USERNAME}:${POSTGRES_PASSWORD}@${POSTGRES_HOSTNAME}:${POSTGRES_PORT}/${SUPABASE_POSTGRES_DATABASE}
      # TODO: Allow configuring VERIFY_JWT per function. This PR might help: https://github.com/supabase/cli/pull/786
      VERIFY_JWT: "${FUNCTIONS_VERIFY_JWT}"
    volumes:
      - supabase-functions-volume:/home/deno/functions:Z
    command:
      - start
      - --main-service
      - /home/deno/functions/main
    networks:
      - nt-supabase
      - nt-databases
      - nt-storage
      - nt-observability
      - nt-webserver

  supabase-analytics:
    env_file:
      - .env.supabase
    container_name: supabase-analytics
    image: supabase/logflare:1.4.0
    healthcheck:
      test:
        ["CMD", "curl", "http://localhost:${SUPABASE_ANALYTICS_PORT}/health"]
      timeout: 5s
      interval: 5s
      retries: 10
    restart: unless-stopped
    # Uncomment to use Big Query backend for analytics
    # volumes:
    #   - type: bind
    #     source: ${PWD}/gcloud.json
    #     target: /opt/app/rel/logflare/bin/gcloud.json
    #     read_only: true
    environment:
      # LOGFLARE_NODE_HOST: 127.0.0.1
      DB_USERNAME: ${DEFAULT_USERNAME}
      DB_DATABASE: ${SUPABASE_POSTGRES_DATABASE}
      DB_HOSTNAME: ${POSTGRES_HOSTNAME}
      DB_PORT: ${POSTGRES_PORT}
      DB_PASSWORD: ${POSTGRES_PASSWORD}
      DB_SCHEMA: _analytics
      # LOGFLARE_API_KEY: ${LOGFLARE_API_KEY}
      # LOGFLARE_SINGLE_TENANT: true
      # LOGFLARE_SUPABASE_MODE: true
      # LOGFLARE_MIN_CLUSTER_SIZE: 1
      # Comment variables to use Big Query backend for analytics
      POSTGRES_BACKEND_URL: postgresql://${DEFAULT_USERNAME}:${POSTGRES_PASSWORD}@${POSTGRES_HOSTNAME}:${POSTGRES_PORT}/${SUPABASE_POSTGRES_DATABASE}
      POSTGRES_BACKEND_SCHEMA: _analytics
      LOGFLARE_FEATURE_FLAG_OVERRIDE: multibackend=true
      # Uncomment to use Big Query backend for analytics
      # GOOGLE_PROJECT_ID: ${GOOGLE_PROJECT_ID}
      # GOOGLE_PROJECT_NUMBER: ${GOOGLE_PROJECT_NUMBER}
    ports:
      - ${SUPABASE_ANALYTICS_HOST_PORT}:${SUPABASE_ANALYTICS_PORT}
    networks:
      - nt-supabase
      - nt-databases
      - nt-storage
      - nt-observability
      - nt-webserver

  # vector:
  #   container_name: supabase-vector
  #   image: timberio/vector:0.28.1-alpine
  #   healthcheck:
  #     test: ['CMD', 'wget', '--no-verbose', '--tries=1', '--spider', 'http://vector:9001/health']
  #     timeout: 5s
  #     interval: 5s
  #     retries: 3
  #   volumes:
  #     - supabase-logs-volume:/etc/vector
  #     - ${DOCKER_SOCKET_LOCATION}:/var/run/docker.sock:ro
  #   environment:
  #     LOGFLARE_API_KEY: ${LOGFLARE_API_KEY}
  #   command: ['--config', 'etc/vector/vector.yml']

volumes:
  supabase-api-volume:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: ${DEFAULT_SUPABASE_DIR}/api
  supabase-functions-volume:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: ${DEFAULT_SUPABASE_DIR}/functions
  supabase-storage-volume:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: ${DEFAULT_STORAGE_DIR}/minio
  # db-config:
